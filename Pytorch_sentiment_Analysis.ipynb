{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03581fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0579, 0.7794, 0.7660],\n",
      "        [0.4059, 0.5663, 0.2166],\n",
      "        [0.3554, 0.9607, 0.4781],\n",
      "        [0.9218, 0.9775, 0.0142],\n",
      "        [0.3850, 0.5911, 0.0251]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26cffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in e:\\users\\hp\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.0.46)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (20.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.0.19)\n",
      "Requirement already satisfied: requests in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.25.1)\n",
      "Requirement already satisfied: filelock in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.59.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in e:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers[torch]) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers[torch]) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: click in e:\\users\\hp\\anaconda3\\lib\\site-packages (from sacremoses->transformers[torch]) (7.1.2)\n",
      "Requirement already satisfied: six in e:\\users\\hp\\anaconda3\\lib\\site-packages (from sacremoses->transformers[torch]) (1.15.0)\n",
      "Requirement already satisfied: joblib in e:\\users\\hp\\anaconda3\\lib\\site-packages (from sacremoses->transformers[torch]) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'E:\\Users\\HP\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97347d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in e:\\users\\hp\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: sacremoses in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: requests in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: filelock in e:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in e:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: six in e:\\users\\hp\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in e:\\users\\hp\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in e:\\users\\hp\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'E:\\Users\\HP\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a419c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cad44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998743534088135}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('i am happy about this code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34d40d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: POSITIVE, with score: 0.9534\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"its a pleasure to know data science.\",\n",
    "           \"hope i don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07dd00f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-win_amd64.whl (423.2 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.41.1-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six~=1.15.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Collecting clang~=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accès refusé: 'E:\\\\Users\\\\HP\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'E:\\Users\\HP\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Requirement already satisfied: wheel~=0.35 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.2-py2.py3-none-any.whl (155 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.2.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30692 sha256=ec44fd7cab30fb78d6939b604d6dba3ab59fbda05dd44271e90f7b4c05a0ea2b\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\f1\\60\\77\\22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=4a4b1173447d4dde12c7b7c8d08448e3d6d9d9d6a8014d0336c6d6bfd0bf207e\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849c5089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4761055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, is this working\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea6113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"is this working.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3421bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2003, 2023, 2551, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d723b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bcf3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995556473731995}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('This code is not simple.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa97498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55dc3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e3035638174a8fa3fb13960fc855bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/638M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bac38a606144ba980bd941d209e542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a63c260a344a43be8875f6e5c5c83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc07e2e00ad451593f327117e1b135e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "# This model only exists in PyTorch, so we use the `from_pt` flag to import that model in TensorFlow.\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8acdbada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.35580480098724365}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"je suis une travailleuse acharnée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4a85603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '3 stars', 'score': 0.5331571102142334}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Soy un poco trabajador\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6737f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91183f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy:', outputs)\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
    "print('softmax torch:', outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20e0fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 numpy: 0.3567\n",
      "Loss2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([1, 0, 0])\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe103090",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor([0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da58546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor([0])\n",
    "loss = nn.CrossEntropyLoss()\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "068e3d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Loss1: 0.4170\n",
      "PyTorch Loss2: 1.8406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
    "print(f'PyTorch Loss2: {l2.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a27749a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class: 0, Y_pred1: 0, Y_pred2: 1\n"
     ]
    }
   ],
   "source": [
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81e2aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting attention\n",
      "  Downloading attention-4.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: numpy>=1.18.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from attention) (1.19.5)\n",
      "Requirement already satisfied: tensorflow>=2.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from attention) (2.6.0)\n",
      "Requirement already satisfied: wheel~=0.35 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (0.37.0)\n",
      "Requirement already satisfied: keras~=2.6 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (2.6.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (1.12.1)\n",
      "Requirement already satisfied: clang~=5.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (5.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (1.41.1)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (0.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (3.3.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'E:\\Users\\HP\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: six~=1.15.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (3.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (2.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (3.19.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (1.12)\n",
      "Requirement already satisfied: gast==0.4.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (2.3.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (58.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (1.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1->attention) (1.3.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (1.26.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1->attention) (3.1.1)\n",
      "Installing collected packages: attention\n",
      "Successfully installed attention-4.0\n"
     ]
    }
   ],
   "source": [
    "pip install attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61015e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21194156 0.57611688 0.21194156]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# example of a function for calculating softmax for a list of numbers\n",
    "from numpy import exp\n",
    "\n",
    "# calculate the softmax of a vector\n",
    "def softmax(vector):\n",
    "\te = exp(vector)\n",
    "\treturn e / e.sum()\n",
    "\n",
    "# define data\n",
    "data = [2, 3, 2]\n",
    "# convert list of numbers to a list of probabilities\n",
    "result = softmax(data)\n",
    "# report the probabilities\n",
    "print(result)\n",
    "# report the sum of the probabilities\n",
    "print(sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bcdab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 10, 64)       16896       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "last_hidden_state (Lambda)      (None, 64)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "attention_score_vec (Dense)     (None, 10, 64)       4096        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "attention_score (Dot)           (None, 10)           0           last_hidden_state[0][0]          \n",
      "                                                                 attention_score_vec[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_weight (Activation)   (None, 10)           0           attention_score[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "context_vector (Dot)            (None, 64)           0           lstm[0][0]                       \n",
      "                                                                 attention_weight[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_output (Concatenate)  (None, 128)          0           context_vector[0][0]             \n",
      "                                                                 last_hidden_state[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "attention_vector (Dense)        (None, 128)          16384       attention_output[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            129         attention_vector[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 37,505\n",
      "Trainable params: 37,505\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 9ms/step - loss: 0.3789\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2585\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2583\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2467\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2503\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2574\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2514\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2447\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2465\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2456\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from attention import Attention\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Dummy data. There is nothing to learn in this example.\n",
    "    num_samples, time_steps, input_dim, output_dim = 100, 10, 1, 1\n",
    "    data_x = np.random.uniform(size=(num_samples, time_steps, input_dim))\n",
    "    data_y = np.random.uniform(size=(num_samples, output_dim))\n",
    "\n",
    "    # Define/compile the model.\n",
    "    model_input = Input(shape=(time_steps, input_dim))\n",
    "    x = LSTM(64, return_sequences=True)(model_input)\n",
    "    x = Attention(32)(x)\n",
    "    x = Dense(1)(x)\n",
    "    model = Model(model_input, x)\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    print(model.summary())\n",
    "\n",
    "    # train.\n",
    "    model.fit(data_x, data_y, epochs=10)\n",
    "\n",
    "    # test save/reload model.\n",
    "    pred1 = model.predict(data_x)\n",
    "    model.save('test_model.h5')\n",
    "    model_h5 = load_model('test_model.h5')\n",
    "    pred2 = model_h5.predict(data_x)\n",
    "    np.testing.assert_almost_equal(pred1, pred2)\n",
    "    print('Success.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9fae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\n",
      "ERROR: No matching distribution found for transformer\n",
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'E:\\Users\\HP\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96379bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement transformer[torch] (from versions: none)\n",
      "ERROR: No matching distribution found for transformer[torch]\n",
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'E:\\Users\\HP\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install transformer[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d814c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution is: [0.95257413 0.04742587]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vector=np.array([6.0,3.0])\n",
    "exp=np.exp(vector)\n",
    "probability=exp/np.sum(exp)\n",
    "print(\"Probability distribution is:\",probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cda2b671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def sig(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "def softmax_cross_entropy(z,y):\n",
    "    if y==1:\n",
    "        return -np.log(z)\n",
    "    else:\n",
    "        return -np.log(1-z)\n",
    "x=np.arange(-9,9,0.1)\n",
    "a=sig(x)\n",
    "softmax1=softmax_cross_entropy(a,1)\n",
    "softmax2=softmax_cross_entropy(a,0)\n",
    "figure,axis=plt.subplots(figsize=(7,7))\n",
    "plt.plot(a,softmax1)\n",
    "plt.plot(a,softmax2)\n",
    "plt.xlabel(\"Cross entropy loss\")\n",
    "plt.ylabel(\"log loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
